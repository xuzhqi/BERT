{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pr4vrEnbmTKf"
   },
   "source": [
    "安装cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113863,
     "status": "ok",
     "timestamp": 1594899328279,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "TJT7nAPq4N2m",
    "outputId": "f29bce5e-a64d-4b92-9a76-f06a17a209e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 284419,
     "status": "ok",
     "timestamp": 1594899657363,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "h-bEYAQVmJpe",
    "outputId": "a4c89834-7345-40b7-d58f-8f2ca28ddb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-16 11:36:13--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 190 [application/octet-stream]\n",
      "Saving to: ‘cuda-ubuntu1804.pin’\n",
      "\n",
      "\r",
      "cuda-ubuntu1804.pin   0%[                    ]       0  --.-KB/s               \r",
      "cuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n",
      "\n",
      "2020-07-16 11:36:13 (3.86 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n",
      "\n",
      "--2020-07-16 11:36:17--  http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1896270068 (1.8G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb’\n",
      "\n",
      "cuda-repo-ubuntu180 100%[===================>]   1.77G  37.6MB/s    in 14s     \n",
      "\n",
      "2020-07-16 11:36:31 (133 MB/s) - ‘cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb’ saved [1896270068/1896270068]\n",
      "\n",
      "Selecting previously unselected package cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01.\n",
      "(Reading database ... 144465 files and directories currently installed.)\n",
      "Preparing to unpack cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb ...\n",
      "Unpacking cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01 (1.0-1) ...\n",
      "Setting up cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01 (1.0-1) ...\n",
      "OK\n",
      "Get:1 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  InRelease\n",
      "Ign:1 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  InRelease\n",
      "Get:2 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release [574 B]\n",
      "Get:2 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release [574 B]\n",
      "Get:3 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release.gpg [833 B]\n",
      "Get:3 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release.gpg [833 B]\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:6 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Packages [23.8 kB]\n",
      "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,005 kB]\n",
      "Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [869 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,279 B]\n",
      "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [89.9 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [43.3 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [104 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,306 kB]\n",
      "Get:25 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,849 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [13.6 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,405 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [8,432 B]\n",
      "Get:29 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [892 kB]\n",
      "Fetched 7,888 kB in 3s (2,513 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  cuda-11-0 cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
      "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
      "  cuda-demo-suite-11-0 cuda-documentation-11-0 cuda-driver-dev-11-0\n",
      "  cuda-gdb-11-0 cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
      "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
      "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
      "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
      "  cuda-nvvp-11-0 cuda-runtime-11-0 cuda-samples-11-0 cuda-sanitizer-11-0\n",
      "  cuda-toolkit-11-0 cuda-tools-11-0 cuda-visual-tools-11-0 libcublas-11-0\n",
      "  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n",
      "  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n",
      "  libcusparse-dev-11-0 libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0\n",
      "  libnvjpeg-dev-11-0\n",
      "The following NEW packages will be installed:\n",
      "  cuda cuda-11-0 cuda-command-line-tools-11-0 cuda-compiler-11-0\n",
      "  cuda-cudart-11-0 cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0\n",
      "  cuda-cupti-dev-11-0 cuda-demo-suite-11-0 cuda-documentation-11-0\n",
      "  cuda-driver-dev-11-0 cuda-gdb-11-0 cuda-libraries-11-0\n",
      "  cuda-libraries-dev-11-0 cuda-memcheck-11-0 cuda-nsight-11-0\n",
      "  cuda-nsight-compute-11-0 cuda-nsight-systems-11-0 cuda-nvcc-11-0\n",
      "  cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0 cuda-nvprune-11-0\n",
      "  cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0 cuda-nvvp-11-0\n",
      "  cuda-runtime-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n",
      "  cuda-tools-11-0 cuda-visual-tools-11-0 libcublas-11-0 libcublas-dev-11-0\n",
      "  libcufft-11-0 libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0\n",
      "  libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0\n",
      "  libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0\n",
      "0 upgraded, 48 newly installed, 0 to remove and 49 not upgraded.\n",
      "Need to get 1,586 MB of archives.\n",
      "After this operation, 4,012 MB of additional disk space will be used.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-11-0 11.0.194-1 [129 kB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-11-0 11.0.194-1 [6,521 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-11-0 11.1.0.229-1 [118 MB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-11-0 10.2.0.218-1 [94.1 MB]\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-11-0 10.2.1.218-1 [39.2 MB]\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-11-0 10.5.0.218-1 [277 MB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-11-0 11.1.0.218-1 [71.2 MB]\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-11-0 11.1.0.218-1 [56.6 MB]\n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-11-0 11.1.0.218-1 [1,391 kB]\n",
      "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-11-0 11.0.2-1 [2,490 B]\n",
      "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-11-0 11.0.2-1 [2,424 B]\n",
      "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-11-0 11.0.194-1 [103 kB]\n",
      "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-11-0 11.0.194-1 [25.0 kB]\n",
      "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-11-0 11.0.194-1 [1,662 kB]\n",
      "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-11-0 11.0.194-1 [21.1 MB]\n",
      "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\n",
      "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-11-0 11.0.2-1 [2,416 B]\n",
      "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-11-0 11.0.194-1 [22.1 kB]\n",
      "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev-11-0 11.1.0.229-1 [120 MB]\n",
      "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-dev-11-0 10.2.0.218-1 [172 MB]\n",
      "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-dev-11-0 10.2.1.218-1 [39.2 MB]\n",
      "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-dev-11-0 10.5.0.218-1 [17.6 MB]\n",
      "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-dev-11-0 11.1.0.218-1 [71.4 MB]\n",
      "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-dev-11-0 11.1.0.218-1 [57.4 MB]\n",
      "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-dev-11-0 11.1.0.218-1 [1,321 kB]\n",
      "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-11-0 11.0.2-1 [2,514 B]\n",
      "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-11-0 11.0.194-1 [10.5 MB]\n",
      "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-11-0 11.0.194-1 [2,276 kB]\n",
      "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-11-0 11.0.194-1 [27.3 MB]\n",
      "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-11-0 11.0.194-1 [3,891 kB]\n",
      "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-11-0 11.0.194-1 [144 kB]\n",
      "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-11-0 11.0.194-1 [1,911 kB]\n",
      "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\n",
      "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-11-0 11.0.194-1 [7,220 kB]\n",
      "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-11-0 11.0.2-1 [2,474 B]\n",
      "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-11-0 11.0.2-1 [3,718 B]\n",
      "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-11-0 11.0.2-1 [3,280 B]\n",
      "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-11-0 11.0.194-1 [119 MB]\n",
      "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\n",
      "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-11-0 11.0.194-1 [115 MB]\n",
      "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-11-0 11.0.2-1 [2,942 B]\n",
      "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-11-0 11.0.2-1 [2,380 B]\n",
      "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-samples-11-0 11.0.194-1 [68.1 MB]\n",
      "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-11-0 11.0.207-1 [59.6 MB]\n",
      "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-0 11.0.2-1 [2,728 B]\n",
      "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-11-0 11.0.167-1 [3,948 kB]\n",
      "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-11-0 11.0.2-1 [2,450 B]\n",
      "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda 11.0.2-1 [2,392 B]\n",
      "Fetched 1,586 MB in 32s (49.1 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 48.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package cuda-cudart-11-0.\n",
      "(Reading database ... 144553 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cuda-cudart-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-11-0.\n",
      "Preparing to unpack .../01-cuda-nvrtc-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package libcublas-11-0.\n",
      "Preparing to unpack .../02-libcublas-11-0_11.1.0.229-1_amd64.deb ...\n",
      "Unpacking libcublas-11-0 (11.1.0.229-1) ...\n",
      "Selecting previously unselected package libcufft-11-0.\n",
      "Preparing to unpack .../03-libcufft-11-0_10.2.0.218-1_amd64.deb ...\n",
      "Unpacking libcufft-11-0 (10.2.0.218-1) ...\n",
      "Selecting previously unselected package libcurand-11-0.\n",
      "Preparing to unpack .../04-libcurand-11-0_10.2.1.218-1_amd64.deb ...\n",
      "Unpacking libcurand-11-0 (10.2.1.218-1) ...\n",
      "Selecting previously unselected package libcusolver-11-0.\n",
      "Preparing to unpack .../05-libcusolver-11-0_10.5.0.218-1_amd64.deb ...\n",
      "Unpacking libcusolver-11-0 (10.5.0.218-1) ...\n",
      "Selecting previously unselected package libcusparse-11-0.\n",
      "Preparing to unpack .../06-libcusparse-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libcusparse-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package libnpp-11-0.\n",
      "Preparing to unpack .../07-libnpp-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libnpp-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package libnvjpeg-11-0.\n",
      "Preparing to unpack .../08-libnvjpeg-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package cuda-libraries-11-0.\n",
      "Preparing to unpack .../09-cuda-libraries-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-runtime-11-0.\n",
      "Preparing to unpack .../10-cuda-runtime-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-runtime-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-cuobjdump-11-0.\n",
      "Preparing to unpack .../11-cuda-cuobjdump-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-driver-dev-11-0.\n",
      "Preparing to unpack .../12-cuda-driver-dev-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-driver-dev-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-cudart-dev-11-0.\n",
      "Preparing to unpack .../13-cuda-cudart-dev-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvcc-11-0.\n",
      "Preparing to unpack .../14-cuda-nvcc-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvcc-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvprune-11-0.\n",
      "Preparing to unpack .../15-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvprune-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-compiler-11-0.\n",
      "Preparing to unpack .../16-cuda-compiler-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-compiler-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-dev-11-0.\n",
      "Preparing to unpack .../17-cuda-nvrtc-dev-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package libcublas-dev-11-0.\n",
      "Preparing to unpack .../18-libcublas-dev-11-0_11.1.0.229-1_amd64.deb ...\n",
      "Unpacking libcublas-dev-11-0 (11.1.0.229-1) ...\n",
      "Selecting previously unselected package libcufft-dev-11-0.\n",
      "Preparing to unpack .../19-libcufft-dev-11-0_10.2.0.218-1_amd64.deb ...\n",
      "Unpacking libcufft-dev-11-0 (10.2.0.218-1) ...\n",
      "Selecting previously unselected package libcurand-dev-11-0.\n",
      "Preparing to unpack .../20-libcurand-dev-11-0_10.2.1.218-1_amd64.deb ...\n",
      "Unpacking libcurand-dev-11-0 (10.2.1.218-1) ...\n",
      "Selecting previously unselected package libcusolver-dev-11-0.\n",
      "Preparing to unpack .../21-libcusolver-dev-11-0_10.5.0.218-1_amd64.deb ...\n",
      "Unpacking libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
      "Selecting previously unselected package libcusparse-dev-11-0.\n",
      "Preparing to unpack .../22-libcusparse-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package libnpp-dev-11-0.\n",
      "Preparing to unpack .../23-libnpp-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libnpp-dev-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package libnvjpeg-dev-11-0.\n",
      "Preparing to unpack .../24-libnvjpeg-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
      "Selecting previously unselected package cuda-libraries-dev-11-0.\n",
      "Preparing to unpack .../25-cuda-libraries-dev-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-cupti-11-0.\n",
      "Preparing to unpack .../26-cuda-cupti-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-cupti-dev-11-0.\n",
      "Preparing to unpack .../27-cuda-cupti-dev-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvdisasm-11-0.\n",
      "Preparing to unpack .../28-cuda-nvdisasm-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-gdb-11-0.\n",
      "Preparing to unpack .../29-cuda-gdb-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-gdb-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-memcheck-11-0.\n",
      "Preparing to unpack .../30-cuda-memcheck-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-memcheck-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvprof-11-0.\n",
      "Preparing to unpack .../31-cuda-nvprof-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvprof-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvtx-11-0.\n",
      "Preparing to unpack .../32-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvtx-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-sanitizer-11-0.\n",
      "Preparing to unpack .../33-cuda-sanitizer-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-sanitizer-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-command-line-tools-11-0.\n",
      "Preparing to unpack .../34-cuda-command-line-tools-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-nsight-compute-11-0.\n",
      "Preparing to unpack .../35-cuda-nsight-compute-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-nsight-systems-11-0.\n",
      "Preparing to unpack .../36-cuda-nsight-systems-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-nsight-11-0.\n",
      "Preparing to unpack .../37-cuda-nsight-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-nvml-dev-11-0.\n",
      "Preparing to unpack .../38-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvvp-11-0.\n",
      "Preparing to unpack .../39-cuda-nvvp-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-nvvp-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-visual-tools-11-0.\n",
      "Preparing to unpack .../40-cuda-visual-tools-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-visual-tools-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-tools-11-0.\n",
      "Preparing to unpack .../41-cuda-tools-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-tools-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-samples-11-0.\n",
      "Preparing to unpack .../42-cuda-samples-11-0_11.0.194-1_amd64.deb ...\n",
      "Unpacking cuda-samples-11-0 (11.0.194-1) ...\n",
      "Selecting previously unselected package cuda-documentation-11-0.\n",
      "Preparing to unpack .../43-cuda-documentation-11-0_11.0.207-1_amd64.deb ...\n",
      "Unpacking cuda-documentation-11-0 (11.0.207-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-11-0.\n",
      "Preparing to unpack .../44-cuda-toolkit-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-toolkit-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda-demo-suite-11-0.\n",
      "Preparing to unpack .../45-cuda-demo-suite-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-demo-suite-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-11-0.\n",
      "Preparing to unpack .../46-cuda-11-0_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda-11-0 (11.0.2-1) ...\n",
      "Selecting previously unselected package cuda.\n",
      "Preparing to unpack .../47-cuda_11.0.2-1_amd64.deb ...\n",
      "Unpacking cuda (11.0.2-1) ...\n",
      "Setting up cuda-sanitizer-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-memcheck-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-nvprune-11-0 (11.0.167-1) ...\n",
      "Setting up libcufft-11-0 (10.2.0.218-1) ...\n",
      "Setting up cuda-nsight-11-0 (11.0.194-1) ...\n",
      "Setting up libcusparse-11-0 (11.1.0.218-1) ...\n",
      "Setting up libcublas-11-0 (11.1.0.229-1) ...\n",
      "Setting up cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
      "Setting up libcusolver-11-0 (10.5.0.218-1) ...\n",
      "Setting up cuda-nvrtc-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-nvprof-11-0 (11.0.194-1) ...\n",
      "Setting up libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
      "Setting up cuda-nvtx-11-0 (11.0.167-1) ...\n",
      "Setting up libnpp-11-0 (11.1.0.218-1) ...\n",
      "Setting up libcurand-11-0 (10.2.1.218-1) ...\n",
      "Setting up libcublas-dev-11-0 (11.1.0.229-1) ...\n",
      "Setting up cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
      "Setting up libcurand-dev-11-0 (10.2.1.218-1) ...\n",
      "Setting up libnpp-dev-11-0 (11.1.0.218-1) ...\n",
      "Setting up cuda-nvvp-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
      "Setting up libnvjpeg-11-0 (11.1.0.218-1) ...\n",
      "Setting up cuda-driver-dev-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-cudart-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
      "Setting up libcufft-dev-11-0 (10.2.0.218-1) ...\n",
      "Setting up libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
      "Setting up cuda-gdb-11-0 (11.0.194-1) ...\n",
      "Setting up libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
      "Setting up cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-libraries-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-visual-tools-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-nvcc-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-runtime-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-samples-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-demo-suite-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-compiler-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-documentation-11-0 (11.0.207-1) ...\n",
      "Setting up cuda-cupti-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
      "Setting up cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-tools-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-toolkit-11-0 (11.0.2-1) ...\n",
      "Setting up cuda-11-0 (11.0.2-1) ...\n",
      "Setting up cuda (11.0.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
    "!sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
    "!sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub\n",
    "!sudo apt-get update\n",
    "!sudo apt-get -y install cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFkTjvIsmReg"
   },
   "source": [
    "安装mxnet和gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 346434,
     "status": "ok",
     "timestamp": 1594899765043,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "cVzGZo8lmqJb",
    "outputId": "587d63d5-01bb-4319-d111-20e9d1d8876b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dist.mxnet.io/python\n",
      "Collecting mxnet-cu100==1.6.0\n",
      "\u001b[?25l  Downloading https://repo.mxnet.io/dist/python/cu100/mxnet_cu100-1.6.0-py2.py3-none-manylinux1_x86_64.whl (695.0MB)\n",
      "\u001b[K     |████████████████████████████████| 695.0MB 26kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.6.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.6.0) (2.23.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (2.10)\n",
      "Installing collected packages: graphviz, mxnet-cu100\n",
      "  Found existing installation: graphviz 0.10.1\n",
      "    Uninstalling graphviz-0.10.1:\n",
      "      Successfully uninstalled graphviz-0.10.1\n",
      "Successfully installed graphviz-0.8.4 mxnet-cu100-1.6.0\n",
      "Collecting gluonnlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 3.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470033 sha256=b69fe22f4a17b4f45c01a18900818d27b47566ac9902f4486203ad67cfff7875\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n",
      "Successfully built gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "Successfully installed gluonnlp-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade mxnet-cu100==1.6.0 -f https://dist.mxnet.io/python\n",
    "!pip install --upgrade gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 346998,
     "status": "ok",
     "timestamp": 1594899767059,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "u-bb5cxQuZKv",
    "outputId": "f16788f2-92e5-4b77-f89d-9bce845b51d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\t\t\t\t    index.rst\n",
      "aclImdb_v1.tar.gz\t\t    labeledTrainData.tsv\n",
      "attention-nlp.png\t\t    log_MRPC.txt\n",
      "base_0.params\t\t\t    log_SST.txt\n",
      "base_1.params\t\t\t    log_STS-B.txt\n",
      "base_2.params\t\t\t    lr5_eight_base_0.params\n",
      "base_3.params\t\t\t    lr5_eight_base_1.params\n",
      "base_4.params\t\t\t    lr5_eight_base_2.params\n",
      "bert\t\t\t\t    output_dir\n",
      "bert-embed.png\t\t\t    self_attentive_sentence_embedding.ipynb\n",
      "BERT_finetune_base.ipynb\t    testDataset_8.tsv\n",
      "bert_imdb.ipynb\t\t\t    testDataset_multi.tsv\n",
      "BERT_inference_base.ipynb\t    testDataset.tsv\n",
      "bert.ipynb\t\t\t    test.tsv\n",
      "bert.png\t\t\t    trainDataset_8.tsv\n",
      "bert-sentence-pair.png\t\t    trainDataset_multi.tsv\n",
      "Bi-LSTM-Rep.png\t\t\t    tri_base_0.params\n",
      "dev.tsv\t\t\t\t    tri_base_1.params\n",
      "eight_base_0.params\t\t    tri_base_2.params\n",
      "eight_base_1.params\t\t    tri_base_3.params\n",
      "eight_base_2.params\t\t    tri_base_4.params\n",
      "eight_base_3.params\t\t    try0.tsv\n",
      "eight_base_4.params\t\t    Untitled\n",
      "elmo_sentence_representation.ipynb  Untitled0.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/sentence_embedding\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXCshe-nm3-i"
   },
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 354916,
     "status": "ok",
     "timestamp": 1594899776056,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "D3_0Cp0lm6NI"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from gluonnlp.calibration import BertLayerCollector\n",
    "# this notebook assumes that all required scripts are already\n",
    "# downloaded from the corresponding tutorial webpage on http://gluon-nlp.mxnet.io\n",
    "\n",
    "from bert import data\n",
    "\n",
    "nlp.utils.check_version('0.8.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msci15SxnA4R"
   },
   "source": [
    "设置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353549,
     "status": "ok",
     "timestamp": 1594899776058,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "5305zYgdnDZs"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "# change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4x9DI9qBnG57"
   },
   "source": [
    "导入BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 374590,
     "status": "ok",
     "timestamp": 1594899798015,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "X9wnlCGAnIs_",
    "outputId": "aded222f-6bc1-48da-9259-9a542d693fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /root/.mxnet/models/7826745781873590530/7826745781873590530_book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
      "Downloading /root/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip051d5d59-1afe-4d59-9841-cf0cf01022f6 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n",
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                        pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                        use_decoder=False, use_classifier=False)\n",
    "print(bert_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1o4YZWWsnL3R"
   },
   "source": [
    "将模型用于分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1594899799414,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "d19vGBRfnV0F"
   },
   "outputs": [],
   "source": [
    "bert_classifier = nlp.model.BERTClassifier(bert_base, num_classes=8, dropout=0.1)\n",
    "# only need to initialize the classifier layer.\n",
    "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "bert_classifier.hybridize(static_alloc=True)\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = mx.gluon.loss.SoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWBturaVnXBl"
   },
   "source": [
    "导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1910,
     "status": "ok",
     "timestamp": 1594899799949,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "Dki8ISFrn2lc",
    "outputId": "7dde8cfa-f19f-4183-ae91-36cb72549f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tsentiment\treview\n",
      "\n",
      "5814_8\t8\tWith all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\n",
      "\n",
      "2381_9\t9\t\"\\The Classic War of the Worlds\\\"\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\"\"critics\\\"\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\"\"critics\\\"\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\"\"critics\\\"\" perceive to be its shortcomings.\"\"\"\n",
      "\n",
      "7759_3\t3\tThe film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . In addition , a security agent (Stacy Haiduk) and her mate (Brian Wimmer) fight hardly against the carnivorous Smilodons. The Sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. The giant animals savagely are stalking its prey and the group run afoul and fight against one nature's most fearsome predators. Furthermore a third Sabretooth more dangerous and slow stalks its victims.<br /><br />The movie delivers the goods with lots of blood and gore as beheading, hair-raising chills,full of scares when the Sabretooths appear with mediocre special effects.The story provides exciting and stirring entertainment but it results to be quite boring .The giant animals are majority made by computer generator and seem totally lousy .Middling performances though the players reacting appropriately to becoming food.Actors give vigorously physical performances dodging the beasts ,running,bound and leaps or dangling over walls . And it packs a ridiculous final deadly scene. No for small kids by realistic,gory and violent attack scenes . Other films about Sabretooths or Smilodon are the following : ¨Sabretooth(2002)¨by James R Hickox with Vanessa Angel, David Keith and John Rhys Davies and the much better ¨10.000 BC(2006)¨ by Roland Emmerich with with Steven Strait, Cliff Curtis and Camilla Belle. This motion picture filled with bloody moments is badly directed by George Miller and with no originality because takes too many elements from previous films. Miller is an Australian director usually working for television (Tidal wave, Journey to the center of the earth, and many others) and occasionally for cinema ( The man from Snowy river, Zeus and Roxanne,Robinson Crusoe ). Rating : Below average, bottom of barrel.\n",
      "\n",
      "3630_4\t4\t\"It must be assumed that those who praised this film (\\the greatest filmed opera ever,\\\"\" didn't I read somewhere?) either don't care for opera, don't care for Wagner, or don't care about anything except their desire to appear Cultured. Either as a representation of Wagner's swan-song, or as a movie, this strikes me as an unmitigated disaster, with a leaden reading of the score matched to a tricksy, lugubrious realisation of the text.<br /><br />It's questionable that people with ideas as to what an opera (or, for that matter, a play, especially one by Shakespeare) is \\\"\"about\\\"\" should be allowed anywhere near a theatre or film studio; Syberberg, very fashionably, but without the smallest justification from Wagner's text, decided that Parsifal is \\\"\"about\\\"\" bisexual integration, so that the title character, in the latter stages, transmutes into a kind of beatnik babe, though one who continues to sing high tenor -- few if any of the actors in the film are the singers, and we get a double dose of Armin Jordan, the conductor, who is seen as the face (but not heard as the voice) of Amfortas, and also appears monstrously in double exposure as a kind of Batonzilla or Conductor Who Ate Monsalvat during the playing of the Good Friday music -- in which, by the way, the transcendant loveliness of nature is represented by a scattering of shopworn and flaccid crocuses stuck in ill-laid turf, an expedient which baffles me. In the theatre we sometimes have to piece out such imperfections with our thoughts, but I can't think why Syberberg couldn't splice in, for Parsifal and Gurnemanz, mountain pasture as lush as was provided for Julie Andrews in Sound of Music...<br /><br />The sound is hard to endure, the high voices and the trumpets in particular possessing an aural glare that adds another sort of fatigue to our impatience with the uninspired conducting and paralytic unfolding of the ritual. Someone in another review mentioned the 1951 Bayreuth recording, and Knappertsbusch, though his tempi are often very slow, had what Jordan altogether lacks, a sense of pulse, a feeling for the ebb and flow of the music -- and, after half a century, the orchestral sound in that set, in modern pressings, is still superior to this film.\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsv_file = io.open('trainDataset_8.tsv', encoding='utf-8')\n",
    "for i in range(5):\n",
    "    print(tsv_file.readline())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAhkELhIoDiP"
   },
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2976,
     "status": "ok",
     "timestamp": 1594899801022,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "3SwLEpg_oFgH",
    "outputId": "8aba7149-0a00-4b15-ea09-60c06479cf27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a uk edition to this show which is rather less extravagant than the US version. The person concerned will get a new kitchen or perhaps bedroom and bathroom and is wonderfully grateful for what they have got. The US version of this show is everything that reality TV shouldn't be. Instead of making a few improvements to a house which the occupants could not afford or do themselves the entire house gets rebuilt. I do not know if this show is trying to show what a lousy welfare system exists in the US or if you beg hard enough you will receive. The rather vulgar product placement that takes place, particularly by Sears, is also uncalled for. Rsther than turning one family in a deprived area into potential millionaires, it would be far better to help the community as a whole where instead of spending the hundreds of thousands of dollars on one home, build something for the whole community ..... perhaps a place where diy and power tools can be borrowed and returned along with building materials so that everyone can benefit should they want to. Giving it all to one person can cause enormous resentment among the rest of the local community who still live in the same run down houses.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Skip the first line, which is the schema\n",
    "num_discard_samples = 1\n",
    "# Split fields by tabs\n",
    "field_separator = nlp.data.Splitter('\\t')\n",
    "sample_splitter = nlp.data.Splitter('\\n')\n",
    "# Fields to select from the file\n",
    "field_indices = [2,1]\n",
    "data_train_raw = nlp.data.TSVDataset(filename='trainDataset_8.tsv',\n",
    "                  sample_splitter=sample_splitter,\n",
    "                  field_separator=field_separator,\n",
    "                  num_discard_samples=num_discard_samples,\n",
    "                  field_indices=field_indices)\n",
    "sample_id = 100\n",
    "# Sentence\n",
    "print(data_train_raw[sample_id][0])\n",
    "# label\n",
    "print(data_train_raw[sample_id][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2970,
     "status": "ok",
     "timestamp": 1594899801023,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "Hjc6t8QX4Ktf",
    "outputId": "ec549753-0a68-44b1-cf1e-77f77bc0aecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  2045  2003  1037  2866  3179  2000  2023  2265  2029  2003  2738\n",
      "  2625 27856  2084  1996  2149  2544  1012  1996  2711  4986  2097  2131\n",
      "  1037  2047  3829  2030  3383  5010  1998  5723  1998  2003  6919  2135\n",
      "  8794  2005  2054  2027  2031  2288  1012  1996  2149  2544  1997  2023\n",
      "  2265  2003  2673  2008  4507  2694  5807  1005  1056  2022  1012  2612\n",
      "  1997  2437  1037  2261  8377  2000  1037  2160  2029  1996 18837  2071\n",
      "  2025  8984  2030  2079  3209  1996  2972  2160  4152  7183  1012  1045\n",
      "  2079  2025  2113  2065  2023  2265  2003  2667  2000  2265  2054  1037\n",
      " 10223  6508  7574  2291  6526  1999  1996  2149  2030  2065  2017 11693\n",
      "  2524  2438  2017  2097  4374  1012  1996  2738 29364  4031 11073  2008\n",
      "  3138  2173  1010  3391  2011 18493  1010     3]\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "valid length = \n",
      "128\n",
      "label = \n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "\n",
    "# The maximum length of an input sequence\n",
    "max_len = 128\n",
    "\n",
    "# The labels for the three classes \n",
    "all_labels = [\"1\", \"2\", \"3\", \"4\", \"7\", \"8\", \"9\", \"10\"]\n",
    "\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "# for regression task, set class_labels=None\n",
    "# for inference without label available, set has_label=False\n",
    "pair = False\n",
    "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                        class_labels=all_labels,\n",
    "                        has_label=True,\n",
    "                        pad=True,\n",
    "                        pair=pair)\n",
    "data_train = data_train_raw.transform(transform)\n",
    "\n",
    "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "print('segment ids = \\n%s'%data_train[sample_id][1])\n",
    "print('valid length = \\n%s'%data_train[sample_id][2])\n",
    "print('label = \\n%s'%data_train[sample_id][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13949,
     "status": "ok",
     "timestamp": 1594899812009,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "2jdN3FzWCLnc",
    "outputId": "32bf4699-9035-4bc9-8999-fe64a7254ba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10322582434020903179, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4324898605934026055\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 15717706960708396224\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9836100352\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 18292334621071240024\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-i-fq1b4vRK"
   },
   "source": [
    "微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2687505,
     "status": "ok",
     "timestamp": 1594826693608,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "mlWddefZ4gvh",
    "outputId": "d07aa043-8da9-4fe3-9507-02db78df3c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/1245] loss=1.4154, lr=0.0000500, acc=0.443\n",
      "[Epoch 0 Batch 200/1245] loss=1.3708, lr=0.0000500, acc=0.454\n",
      "[Epoch 0 Batch 300/1245] loss=1.3712, lr=0.0000500, acc=0.459\n",
      "[Epoch 0 Batch 400/1245] loss=1.4057, lr=0.0000500, acc=0.456\n",
      "[Epoch 0 Batch 500/1245] loss=1.4062, lr=0.0000500, acc=0.451\n",
      "[Epoch 0 Batch 600/1245] loss=1.3942, lr=0.0000500, acc=0.450\n",
      "[Epoch 0 Batch 700/1245] loss=1.4142, lr=0.0000500, acc=0.448\n",
      "[Epoch 0 Batch 800/1245] loss=1.3969, lr=0.0000500, acc=0.447\n",
      "[Epoch 0 Batch 900/1245] loss=1.3736, lr=0.0000500, acc=0.448\n",
      "[Epoch 0 Batch 1000/1245] loss=1.3957, lr=0.0000500, acc=0.449\n",
      "[Epoch 0 Batch 1100/1245] loss=1.3856, lr=0.0000500, acc=0.450\n",
      "[Epoch 0 Batch 1200/1245] loss=1.3811, lr=0.0000500, acc=0.450\n",
      "[Epoch 1 Batch 100/1245] loss=1.1634, lr=0.0000500, acc=0.527\n",
      "[Epoch 1 Batch 200/1245] loss=1.1810, lr=0.0000500, acc=0.525\n",
      "[Epoch 1 Batch 300/1245] loss=1.2054, lr=0.0000500, acc=0.520\n",
      "[Epoch 1 Batch 400/1245] loss=1.1856, lr=0.0000500, acc=0.522\n",
      "[Epoch 1 Batch 500/1245] loss=1.1816, lr=0.0000500, acc=0.523\n",
      "[Epoch 1 Batch 600/1245] loss=1.1882, lr=0.0000500, acc=0.524\n",
      "[Epoch 1 Batch 700/1245] loss=1.2112, lr=0.0000500, acc=0.521\n",
      "[Epoch 1 Batch 800/1245] loss=1.2150, lr=0.0000500, acc=0.518\n",
      "[Epoch 1 Batch 900/1245] loss=1.2063, lr=0.0000500, acc=0.518\n",
      "[Epoch 1 Batch 1000/1245] loss=1.1798, lr=0.0000500, acc=0.518\n",
      "[Epoch 1 Batch 1100/1245] loss=1.2045, lr=0.0000500, acc=0.518\n",
      "[Epoch 1 Batch 1200/1245] loss=1.2135, lr=0.0000500, acc=0.517\n",
      "[Epoch 2 Batch 100/1245] loss=0.9545, lr=0.0000500, acc=0.616\n",
      "[Epoch 2 Batch 200/1245] loss=0.9919, lr=0.0000500, acc=0.602\n",
      "[Epoch 2 Batch 300/1245] loss=0.9516, lr=0.0000500, acc=0.606\n",
      "[Epoch 2 Batch 400/1245] loss=0.9654, lr=0.0000500, acc=0.605\n",
      "[Epoch 2 Batch 500/1245] loss=0.9649, lr=0.0000500, acc=0.605\n",
      "[Epoch 2 Batch 600/1245] loss=1.0006, lr=0.0000500, acc=0.603\n",
      "[Epoch 2 Batch 700/1245] loss=0.9939, lr=0.0000500, acc=0.603\n",
      "[Epoch 2 Batch 800/1245] loss=0.9793, lr=0.0000500, acc=0.602\n",
      "[Epoch 2 Batch 900/1245] loss=1.0031, lr=0.0000500, acc=0.600\n",
      "[Epoch 2 Batch 1000/1245] loss=1.0127, lr=0.0000500, acc=0.599\n",
      "[Epoch 2 Batch 1100/1245] loss=1.0289, lr=0.0000500, acc=0.597\n",
      "[Epoch 2 Batch 1200/1245] loss=1.0041, lr=0.0000500, acc=0.597\n",
      "[Epoch 3 Batch 100/1245] loss=0.8048, lr=0.0000500, acc=0.668\n",
      "[Epoch 3 Batch 200/1245] loss=0.8088, lr=0.0000500, acc=0.673\n",
      "[Epoch 3 Batch 300/1245] loss=0.7491, lr=0.0000500, acc=0.678\n",
      "[Epoch 3 Batch 400/1245] loss=0.7708, lr=0.0000500, acc=0.680\n",
      "[Epoch 3 Batch 500/1245] loss=0.7872, lr=0.0000500, acc=0.681\n",
      "[Epoch 3 Batch 600/1245] loss=0.7964, lr=0.0000500, acc=0.680\n",
      "[Epoch 3 Batch 700/1245] loss=0.8038, lr=0.0000500, acc=0.680\n",
      "[Epoch 3 Batch 800/1245] loss=0.7930, lr=0.0000500, acc=0.679\n",
      "[Epoch 3 Batch 900/1245] loss=0.8088, lr=0.0000500, acc=0.678\n",
      "[Epoch 3 Batch 1000/1245] loss=0.8598, lr=0.0000500, acc=0.677\n",
      "[Epoch 3 Batch 1100/1245] loss=0.8239, lr=0.0000500, acc=0.676\n",
      "[Epoch 3 Batch 1200/1245] loss=0.8181, lr=0.0000500, acc=0.676\n",
      "[Epoch 4 Batch 100/1245] loss=0.6298, lr=0.0000500, acc=0.747\n",
      "[Epoch 4 Batch 200/1245] loss=0.6301, lr=0.0000500, acc=0.748\n",
      "[Epoch 4 Batch 300/1245] loss=0.6168, lr=0.0000500, acc=0.747\n",
      "[Epoch 4 Batch 400/1245] loss=0.6202, lr=0.0000500, acc=0.750\n",
      "[Epoch 4 Batch 500/1245] loss=0.6313, lr=0.0000500, acc=0.751\n",
      "[Epoch 4 Batch 600/1245] loss=0.6503, lr=0.0000500, acc=0.749\n",
      "[Epoch 4 Batch 700/1245] loss=0.6567, lr=0.0000500, acc=0.746\n",
      "[Epoch 4 Batch 800/1245] loss=0.6555, lr=0.0000500, acc=0.745\n",
      "[Epoch 4 Batch 900/1245] loss=0.6779, lr=0.0000500, acc=0.743\n",
      "[Epoch 4 Batch 1000/1245] loss=0.6647, lr=0.0000500, acc=0.741\n",
      "[Epoch 4 Batch 1100/1245] loss=0.6587, lr=0.0000500, acc=0.740\n",
      "[Epoch 4 Batch 1200/1245] loss=0.6941, lr=0.0000500, acc=0.739\n"
     ]
    }
   ],
   "source": [
    "# The hyperparameters\n",
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "\n",
    "# The FixedBucketSampler and the DataLoader for making the mini-batches\n",
    "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_train],\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "bert_dataloader = mx.gluon.data.DataLoader(data_train, batch_sampler=train_sampler)\n",
    "\n",
    "trainer = mx.gluon.Trainer(bert_classifier.collect_params(), 'adam',\n",
    "                           {'learning_rate': lr, 'epsilon': 1e-9})\n",
    "\n",
    "# Collect all differentiable parameters\n",
    "# `grad_req == 'null'` indicates no gradients are calculated (e.g. constant parameters)\n",
    "# The gradients for these params are clipped later\n",
    "params = [p for p in bert_classifier.collect_params().values() if p.grad_req != 'null']\n",
    "grad_clip = 1\n",
    "\n",
    "# Training the model with only three epochs\n",
    "log_interval = 100\n",
    "num_epochs = 5\n",
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(bert_dataloader):\n",
    "        with mx.autograd.record():\n",
    "\n",
    "            # Load the data to the GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # 前馈运算 -> forward\n",
    "            out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            # 做均值运算\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # And backwards computation\n",
    "        ls.backward()\n",
    "\n",
    "        # 梯度截断\n",
    "        trainer.allreduce_grads()# 梯度累加\n",
    "        nlp.utils.clip_grad_global_norm(params, 1)# 门限为1\n",
    "        trainer.update(1) # 因为ls已经mean()了,所以这里的batch_size=1\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                         .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "    #导出模型\n",
    "    filename=\"./lr5_eight_base_\"+str(epoch_id)+\".params\"\n",
    "    nlp.utils.save_parameters(bert_classifier,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szCW6tuLWRWx"
   },
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7HiPENbtqk8"
   },
   "source": [
    "测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X7997qYVRZa"
   },
   "outputs": [],
   "source": [
    "#加载验证集\n",
    "# Skip the first line, which is the schema\n",
    "num_discard_samples = 1\n",
    "# Split fields by tabs\n",
    "field_separator = nlp.data.Splitter('\\t')\n",
    "sample_splitter = nlp.data.Splitter('\\n')\n",
    "# Fields to select from the file\n",
    "field_indices=[2,1]\n",
    "data_test_raw = nlp.data.TSVDataset(filename='testDataset_8.tsv',\n",
    "                  sample_splitter=sample_splitter,\n",
    "                  field_separator=field_separator,\n",
    "                  num_discard_samples=num_discard_samples,\n",
    "                  field_indices=field_indices)\n",
    "data_test = data_test_raw.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361200,
     "status": "ok",
     "timestamp": 1594827151815,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "ol2X2KzxVR8-",
    "outputId": "eb141b55-c76f-4ea3-8d0f-d6d27a4a6808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation acc: 0.42848837209302326\n",
      "Epoch 1 validation acc: 0.4251937984496124\n",
      "Epoch 2 validation acc: 0.4145348837209302\n",
      "Epoch 3 validation acc: 0.40930232558139534\n",
      "Epoch 4 validation acc: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "#在验证集上的精度\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "test_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_test],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_sampler=test_sampler)\n",
    "\n",
    "validation = nlp.model.BERTClassifier(bert_base, num_classes=8, dropout=0.1)\n",
    "validation.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "validation.hybridize(static_alloc=True)\n",
    "\n",
    "for epoch_id in range(num_epochs):\n",
    "  filename=\"./lr5_eight_base_\"+str(epoch_id)+\".params\"\n",
    "  nlp.utils.load_parameters(validation,filename,ctx=ctx)\n",
    "  metric.reset()\n",
    "  for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(test_dataloader):\n",
    "    with mx.autograd.record():\n",
    "      # Load the data to the GPU\n",
    "      token_ids = token_ids.as_in_context(ctx)\n",
    "      valid_length = valid_length.as_in_context(ctx)\n",
    "      segment_ids = segment_ids.as_in_context(ctx)\n",
    "      label = label.as_in_context(ctx)\n",
    "\n",
    "      # Forward computation\n",
    "      out = validation(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "    metric.update([label], [out])\n",
    "  print('Epoch '+str(epoch_id)+' validation acc:',metric.get()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-_Qq3KVlIe4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "# change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "ctx = mx.gpu(0)\n",
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                        pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                        use_decoder=False, use_classifier=False)\n",
    "bert_classifier = nlp.model.BERTClassifier(bert_base, num_classes=8, dropout=0.1)\n",
    "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "bert_classifier.hybridize(static_alloc=True)\n",
    "filename=\"./lr5_eight_base_4.params\"\n",
    "nlp.utils.load_parameters(bert_classifier,filename,ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3460,
     "status": "ok",
     "timestamp": 1594829184722,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "9reCdlAjMzh6",
    "outputId": "d9b97b8f-8a03-409f-faef-0bf35b18ad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\t\t\t\t    labeledTrainData.tsv\n",
      "aclImdb_v1.tar.gz\t\t    log_MRPC.txt\n",
      "attention-nlp.png\t\t    log_SST.txt\n",
      "base_0.params\t\t\t    log_STS-B.txt\n",
      "base_1.params\t\t\t    lr5_eight_base_0.params\n",
      "base_2.params\t\t\t    lr5_eight_base_1.params\n",
      "base_3.params\t\t\t    lr5_eight_base_2.params\n",
      "base_4.params\t\t\t    lr5_eight_base_3.params\n",
      "bert\t\t\t\t    lr5_eight_base_4.params\n",
      "bert-embed.png\t\t\t    output_dir\n",
      "BERT_finetune_base.ipynb\t    self_attentive_sentence_embedding.ipynb\n",
      "bert_imdb.ipynb\t\t\t    testDataset_8.tsv\n",
      "BERT_inference_base.ipynb\t    testDataset_multi.tsv\n",
      "bert.ipynb\t\t\t    testDataset.tsv\n",
      "bert.png\t\t\t    test.tsv\n",
      "bert-sentence-pair.png\t\t    trainDataset_8.tsv\n",
      "Bi-LSTM-Rep.png\t\t\t    trainDataset_multi.tsv\n",
      "dev.tsv\t\t\t\t    tri_base_0.params\n",
      "eight_base_0.params\t\t    tri_base_1.params\n",
      "eight_base_1.params\t\t    tri_base_2.params\n",
      "eight_base_2.params\t\t    tri_base_3.params\n",
      "eight_base_3.params\t\t    tri_base_4.params\n",
      "eight_base_4.params\t\t    try0.tsv\n",
      "elmo_sentence_representation.ipynb  Untitled\n",
      "index.rst\t\t\t    Untitled0.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/sentence_embedding\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2890,
     "status": "ok",
     "timestamp": 1594829664980,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "M_mtvqatlqFv",
    "outputId": "dcc58de6-4c24-4d28-d573-b02afa9c355d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"\"\"How to turn a chewy new flower into a new flower is that it must not be a science fiction suspense. A happy day is a good attempt, as is Palm Springs, but obviously the latter has something more. At least in my opinion, a relationship is an appointment to go to death, without the determination to die, it is better to be trapped in reincarnation.\"\"\"', '8']\n"
     ]
    }
   ],
   "source": [
    "field_separator = nlp.data.Splitter('\\t')\n",
    "# test_sentence = input('please enter the sentence')\n",
    "# with open('test.csv', 'w', newline='') as csv_file:\n",
    "#     writer = csv.writer(csv_file, dialect='excel')\n",
    "#     writer.writerow('test_sentence')\n",
    "data_inference_row = nlp.data.TSVDataset(filename='test.tsv',\n",
    "                field_separator=field_separator)\n",
    "print(data_inference_row[1])\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "max_len = 128\n",
    "all_labels = [\"1\", \"2\", \"3\", \"4\", \"7\", \"8\", \"9\", \"10\"]\n",
    "pair = False\n",
    "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                        class_labels=all_labels,\n",
    "                        has_label=True,\n",
    "                        pad=True,\n",
    "                        pair=pair)\n",
    "data_inference=data_inference_row.transform(transform)\n",
    "batch_size = 1\n",
    "data_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_inference],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOdBKXQ3PToI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1990,
     "status": "ok",
     "timestamp": 1594829668695,
     "user": {
      "displayName": "陈Nengfu",
      "photoUrl": "",
      "userId": "00098101946458942679"
     },
     "user_tz": -480
    },
    "id": "EkcPdn2ixZQH",
    "outputId": "6eadf5d1-91c3-4067-b58d-ebb33acb0f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"For the Mother of \"The Search for Mom\". Compared with other films of the same type, the biggest feature of this film is the unique laziness of the millennial generation. Unfortunately, there are few climaxes in the story, and there are few golden sentences. The length of 90 minutes also has a long sense of 120 minutes.\"\"\"\n",
      "label:  7\n",
      "\n",
      "[[ 2.9200022  -1.0006231  -0.93910044 -1.7661268  -1.4485964  -0.8727535\n",
      "   0.48444784  3.5936024 ]]\n",
      "<NDArray 1x8 @gpu(0)>\n",
      "\n",
      "[6.0483575]\n",
      "<NDArray 1 @gpu(0)>\n",
      "\"\"\"How to turn a chewy new flower into a new flower is that it must not be a science fiction suspense. A happy day is a good attempt, as is Palm Springs, but obviously the latter has something more. At least in my opinion, a relationship is an appointment to go to death, without the determination to die, it is better to be trapped in reincarnation.\"\"\"\n",
      "label:  8\n",
      "\n",
      "[[-3.3816025 -4.5945015 -3.300514  -1.533656   2.859555   4.007439\n",
      "   3.237679   3.200744 ]]\n",
      "<NDArray 1x8 @gpu(0)>\n",
      "\n",
      "[12.348364]\n",
      "<NDArray 1 @gpu(0)>\n",
      "\"\"\"All in all, this is a movie for kids. We saw it tonight and my child loved it. At one point my kid's excitement was so great that sitting was impossible. However, I am a great fan of A.A. Milne's books which are very subtle and hide a wry intelligence behind the childlike quality of its leading characters. This film was not subtle. It seems a shame that Disney cannot see the benefit of making movies from more of the stories contained in those pages, although perhaps, it doesn't have the permission to use them. I found myself wishing the theater was replaying \\Winnie-the-Pooh and Tigger too\\\"\", instead. The characters voices were very good. I was only really bothered by Kanga. The music, however, was twice as loud in parts than the dialog, and incongruous to the film.<br /><br />As for the story, it was a bit preachy and militant in tone. Overall, I was disappointed, but I would go again just to see the same excitement on my child's face.<br /><br />I liked Lumpy's laugh....\"\"\"\n",
      "label:  4\n",
      "\n",
      "[[ 1.9417703  -0.1918446   0.17288281 -0.36305475 -0.15399675 -0.963321\n",
      "  -0.7174653   0.711184  ]]\n",
      "<NDArray 1x8 @gpu(0)>\n",
      "\n",
      "[4.4883513]\n",
      "<NDArray 1 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "data_loader = mx.gluon.data.DataLoader(data_inference, batch_sampler=data_sampler)\n",
    "for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(data_loader):\n",
    "  token_ids = token_ids.as_in_context(ctx)\n",
    "  valid_length = valid_length.as_in_context(ctx)\n",
    "  segment_ids = segment_ids.as_in_context(ctx)\n",
    "  label = label.as_in_context(ctx)\n",
    "  out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "  print(data_inference_row[batch_id][0])\n",
    "  print('label: ',data_inference_row[batch_id][1])\n",
    "  print(out)\n",
    "  delta = 0\n",
    "  for i in range(8):\n",
    "    delta += (i-5.5)*out[0][i]\n",
    "  predict = 5.5 + delta/8\n",
    "  #print(np.floor(predict))\n",
    "  print(predict)\n",
    "\n",
    "  # if (out.argmax(axis=1))[0]==1:\n",
    "  #   print('inference: 1')\n",
    "  # else:\n",
    "  #   print('inference: 0')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_imdb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
